---
title: "The Office Report"
author: "Carlos Omar Pardo, Antonio Lopez Ruiz, Jose Lopez Torres"
date: "December 3, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Switch to 2 question: List team members and a description of how each contributed to the project.

Explain why you chose this topic, and the questions you are interested in studying.

We (just like over 6 million viewers per episode) have all enjoyed watching this show, and decided to use our data visualization techniques to analyze some complex questions about the series. The following is the initial list that guided our analysis:

1) How many "that's what she said"" gags took place throughout the series?

2) Who are the characters that are mentioned the most in others' dialogues?

3) Who is the character that says the longest words?

4) Who has the most dialogues?

5) Who uses the most crutch words?

6) Who got cut out? Who lost the most scenes due to the editors?

7) What are the groups of characters that share the most screen time?

8) Who stares at the camera the most?

9) Do female characters have as much dialogues as males?

10) As the show progressed, how did ratings change?

11) What characters speak the most throughout the series?

13) Is Michael really smarter than Oscar?

14) Can we visualize how characters interact amongst themselves?

15) Can we identify the most important word for a given character or episode?

Using these questions as a starting point, we dived into our database and expanded it by using information that wasn't already in it. 


## Questions from HW4

### Omar

\textcolor{blue}{It's easy to see there is a decreasing behavior for all the seasons, meaning that most of the scenes contained just a few lines. This situation could be counterintuitive for most of the series, as one would expect constant dialogue between the characters, and therefore scenes with more than one or two lines. However, taking into account \textit{The Office}'s documentary style, it makes sense, because many times there is just one character talking to the camera. For further investigation, it would be interesting to know how long in time are these one-line scenes, and if they can be compared to a typical scene of a different kind series.}

### Jose

From the first plot, I realized that there are some spelling errors and descriptions in the "speaker" variable, which means that we will need to focus on this column and clean it for our analysis.

I think it would also be interesting to look who's interacting on each conversation. Probably Dwight and Michael have more scenes alone in front of the camera and that's why they are so common in the dialogues. How many conversations take place between Pam and Jim, for instance?

From the second plot, I think it'd be interesting to know if there's a relationship between length in characters and actual speech said by each character. I think it would also be interesting to analyze on average who's the smartest (which could be measured as the one using the longest words). Maybe some of the lines describe actions, which might explain their length.

From the last plot, I think it's necessary to add new variations of the joke, as I think these numbers are too low. There might be some punctuation differences, typos or other reasons why there are so few ocurrences, or maybe some of the times when it took place it wasn't scripted.

There's still much more to learn about this dataset, and I am looking forward to working with my teammates to see what other questions come up for the final project.

## Antonio
### End of questions
# Description of Data

Thanks to the show's large number of fans there are several websites dedicated to different aspects of the series. We found a repository from a fan's blog, called Officequotes.net; this repository includes every dialogue from the script, specifying the season, episode and scene in which it was said, as well as its speaker and whether the scene was edited out of the show or not.

The data is stored as a Google Sheet in (https://docs.google.com/spreadsheets/d/18wS5AAwOh8QO95RwHLS95POmSNKA2jjzdt0phrxeAE0/edit#gid=747974), so we reviewed into it to understand the conditions it was in:

First, we found that the 

Furthermore, one of the questions required us to retrieve data that wasn't available on the original dataset. We found ratings at a per-episode level in wikipedia.org (which took this information from tv.com) and copied the information on a csv file. Although the ratings correspond to the original airdate's audience, we assume that this factor is a constant (i.e, it is a fair comparisson to evaluate conclusions about viewership for any episode in the seried based on the rating recieved during its first cast), and used it for our project.


## Describe how the data was collected, how you accessed it, and any other noteworthy features.





# Analysis of data quality

Provide a detailed, well-organized description of data quality, including textual description, graphs, and code.

# Main Analysis

Provide a detailed, well-organized description of your findings, including textual description, graphs, and code. Your focus should be on both the results and the process. Include, as reasonable and relevant, approaches that didn’t work, challenges, the data cleaning process, etc.

# Executive Summary

Provide a short nontechnical summary of the most revealing findings of your analysis written for a nontechnical audience. The length should be approximately two pages (if we were using pages…) Take extra care to clean up your graphs, ensuring that best practices for presentation are followed.

Note: “Presentation” here refers to the style of graph, that is, graphs that are cleaned up for presentation, as opposed to the rough ones we often use for exploratory data analysis. You do not have to present your work to the class! However, you may choose to present your work as your community contribution, in which case you need to email me to set a date before the community contribution due date. (The presentation itself may be later.)

# Interactive component

Select one (or more) of your key findings to present in an interactive format. Be selective in the choices that you present to the user; the idea is that in 5-10 minutes, users should have a good sense of the question(s) that you are interested in and the trends you’ve identified in the data. In other words, they should understand the value of the analysis, be it business value, scientific value, general knowledge, etc.

# Conclusion

Discuss limitations and future directions, lessons learned.



When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
